{"cells":[{"cell_type":"markdown","metadata":{"id":"MMOAOHkOH91J"},"source":["<h1 align=\"center\">\n"," <b>PROYECTO INDIVIDUAL Nº2</b>\n","</h1>\n","\n","# <h1 align=\"center\">**`Siniestros viales`**</h1>\n","<h1 align=\"center\" style=\"color: yellow;\">Londero Walter Oscar</h1>\n","\n","<p align=\"center\">\n","<img src = \"https://static.lajornadaestadodemexico.com/wp-content/uploads/2022/08/Siniestros-viales.jpg\" height = 500>\n","<p>\n","\n","# Proyecto Individual Nº2 - Siniestros Viales\n","\n","## **Descripción del Problema**\n","\n","Los siniestros viales son eventos que involucran vehículos en las vías públicas y pueden tener graves consecuencias. En Buenos Aires, estos incidentes son una preocupación debido al alto volumen de tráfico y densidad poblacional. Reducir las tasas de mortalidad por siniestros viales es crucial para mejorar la seguridad vial. En Argentina, los siniestros viales causan alrededor de 4.000 muertes al año, siendo una de las principales causas de muertes violentas. El Observatorio de Movilidad y Seguridad Vial solicita un proyecto de análisis de datos para ayudar a reducir las víctimas fatales de siniestros viales en Buenos Aires, proporcionando un dataset sobre homicidios en siniestros viales ocurridos entre 2016-2021.\n","\n","El dataset se encuentra en: https://data.buenosaires.gob.ar/dataset/victimas-siniestros-viales\n","\n","### Contexto\n","\n","En Argentina, los siniestros viales causan un alto número de muertes cada año, superando incluso a otras causas de muerte violenta. El Observatorio de Movilidad y Seguridad Vial de Buenos Aires busca reducir estas cifras proporcionando información para tomar medidas efectivas.\n","\n","### Rol a Desarrollar\n","\n","El proyecto implica el análisis de datos sobre homicidios en siniestros viales en Buenos Aires entre 2016 y 2021. El objetivo es proporcionar información que permita a las autoridades locales tomar medidas para reducir la cantidad de víctimas fatales.\n"]},{"cell_type":"markdown","metadata":{"id":"_RRJRjpDH91O"},"source":["# <span style=\"color: #FF9843\">**ETL**</span>"]},{"cell_type":"markdown","metadata":{"id":"pIo_GIodlQ5e"},"source":["## <span style=\"color: #FFDD95\">**Extracción**</span>"]},{"cell_type":"markdown","metadata":{},"source":["_Estas son las Librerias necesarias para la ejecución del Proyecto:_"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!pip freeze > requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('requirements.txt', 'r') as archivo:\n","    contenido = archivo.read()\n","    print(contenido)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":763,"status":"ok","timestamp":1707913604725,"user":{"displayName":"Walter Oscar Londero","userId":"04815395286935470207"},"user_tz":180},"id":"pUJh8UitH91O"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from summarytools import dfSummary\n","import requests\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# URL de exportación de Google Sheets\n","url = 'https://docs.google.com/spreadsheets/d/1nq00jGIZHQ1RLSET43zKnUsMsoFb-pBg/export?format=xlsx'\n","\n","# Nombre del archivo donde se guardará la descarga\n","filename = 'spreadsheet.xlsx'\n","\n","# Hacer la solicitud GET a la URL\n","response = requests.get(url)\n","\n","# Guardar el contenido de la respuesta en un archivo\n","with open(filename, 'wb') as file:\n","    file.write(response.content)\n","\n","print(f'El archivo se ha descargado y guardado como {filename}')"]},{"cell_type":"markdown","metadata":{"id":"dsWHCK8JH91Q"},"source":["## <span style=\"color: #FFDD95\">**Transformación**</span>"]},{"cell_type":"markdown","metadata":{},"source":["### <span style=\"color: #8DECB4\">**1-Explorar y Limpiar Datos**</span>"]},{"cell_type":"markdown","metadata":{"id":"vKqMJXXaH91R"},"source":["****\n","<span style=\"color: #FAEF5D\">Carga de los datos:</span>"]},{"cell_type":"markdown","metadata":{},"source":["Se importa la información de cada hoja del archivo en un df diferente:"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":19057,"status":"ok","timestamp":1707913651684,"user":{"displayName":"Walter Oscar Londero","userId":"04815395286935470207"},"user_tz":180},"id":"W7F7zKH_H91R"},"outputs":[],"source":["# Read the downloaded spreadsheet into DataFrames\n","df_hechos = pd.read_excel(filename, sheet_name='HECHOS')\n","df_victimas = pd.read_excel(filename, sheet_name='VICTIMAS')"]},{"cell_type":"markdown","metadata":{},"source":["Hacemos un primer análisis de la información:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Print DataFrames\n","print(\"Datos de la hoja HECHOS:\")\n","print(df_hechos)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(\"\\nDatos de la hoja VICTIMAS:\")\n","print(df_victimas)"]},{"cell_type":"markdown","metadata":{},"source":["Obtenemos la información general de los df y analizamos tipos de datos y futuras transformaciones:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Obtener información general del DataFrame\n","df_hechos.info()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_victimas.info()"]},{"cell_type":"markdown","metadata":{},"source":["Como el reemplazante \"SD\" de datos nulos posee diferencias con respecto a mayúsculas y minúsculas debemos unificarlos:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_hechos.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Los valores nulos son significativos en el df_hechos en dos columnas principalmente, Altura con 567 valores faltantes y Cruce con 171 faltantes. Se van a conservar las columnas pero se tendra en cuanta para analisis posteriores que puedan involucrar estas columnas."]},{"cell_type":"markdown","metadata":{},"source":["Reemplazar los valores nulos en HORA y HH con 25, debido a que es un tipo numérico y facilmente reconocible posteriormente en el análisisya ya que no corresponde a una hora válida:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reemplazar los valores nulos en las columnas 'HORA' y 'HH' con 0\n","df_hechos['HORA'] = df_hechos['HORA'].fillna('25:00')\n","df_hechos['HH'] = df_hechos['HH'].fillna(25)"]},{"cell_type":"markdown","metadata":{},"source":["Reemplazar los valores nulos en LUGAR_DEL_HECHO, Calle, Altura, Cruce, Direccion Normalizada, VICTIMA, y ACUSADO con 'SD'.\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Reemplazar los valores nulos en las columnas especificadas con 'SD'\n","columns_to_replace_with_sd = ['LUGAR_DEL_HECHO', 'Calle', 'Altura', 'Cruce', 'Dirección Normalizada', 'VICTIMA', 'ACUSADO']\n","df_hechos[columns_to_replace_with_sd] = df_hechos[columns_to_replace_with_sd].fillna('SD')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_victimas.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["El df_victimas no contiene datos nulos."]},{"cell_type":"markdown","metadata":{},"source":["Análisis de columnas con valores NaN"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_hechos[[\"Calle\", \"Altura\", \"Dirección Normalizada\", \"Cruce\"]][:5]"]},{"cell_type":"markdown","metadata":{},"source":["Corroboramos si podemos extraer de la dirección normalizada los datos necesarios para completar la columna Altura y esta información no se encuentra en ningu otro lugar. Por lo que el análisis debe continuar sin estos datos."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Definir las columnas a revisar\n","columns_to_check = ['Calle', 'Altura', 'Dirección Normalizada', 'Cruce']\n","\n","# Contar la cantidad de valores 'SD' en cada columna\n","sd_counts = df_hechos[columns_to_check].apply(lambda x: (x == 'SD').sum())\n","\n","# Mostrar los resultados\n","print(sd_counts)"]},{"cell_type":"markdown","metadata":{},"source":["La columna **`Altura`** posee gran cantidad de datos faltantes y con la informacion que se tine no hay forma de completarla. En este caso la cantidad de faltantes corresponde a más del 80% de los datos. En este caso debemos eliminarla:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Se elimina la columna \"Altura\"\n","df_hechos= df_hechos.drop(\"Altura\", axis=1)\n","df_hechos.columns"]},{"cell_type":"markdown","metadata":{},"source":["Ahora podemos ver si hay información duplicada en nuestro df:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_hechos.duplicated().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_victimas.duplicated().sum()"]},{"cell_type":"markdown","metadata":{},"source":["En los dataframes no hubo entradas repetidas y el shape de los archivos sigue el mismo:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_rows = df_hechos.shape[0]\n","print(\"Número de filas en df_hechos:\", num_rows)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["num_rows = df_victimas.shape[0]\n","print(\"Número de filas en df_victimas:\", num_rows)"]},{"cell_type":"markdown","metadata":{},"source":["Corroboramos la info de elementos nulos en df_victimas:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_victimas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_victimas.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["Renombrar la columna: Se usa el método rename con el parámetro inplace=True para cambiar el nombre de la columna ID_hecho a ID."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Renombrar la columna ID_hecho a ID\n","df_victimas.rename(columns={'ID_hecho': 'ID'}, inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["    Esto será útil para hacer posteriormente el Join."]},{"cell_type":"markdown","metadata":{},"source":["Verificamos que todo esta completo y no tenemos valores nulos en Nuestros DataFrames:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_hechos.isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Verificar el cambio\n","df_victimas.isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["### <span style=\"color: #8DECB4\">**2-Explorar y Transformar Datos**</span>"]},{"cell_type":"markdown","metadata":{"id":"Y-N4Up8ulQ5h"},"source":["****\n","<span style=\"color: #FAEF5D\">Correccón de Mayusculas y Minusculas:</span>"]},{"cell_type":"markdown","metadata":{},"source":["En este apartado se ha realizado la transformación de manera correcta sin ningún inconveniente, la unificación de la información a mayúsculas ayuda a la prolijidad y a evitar errores de escritura en formulas o funciones, evitando así chequear en todo momento el nombre de columnas para no escribir mal."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def convertir_columnas(df):\n","  \"\"\"\n","  Convierte los nombres de las columnas de un DataFrame a mayúsculas y elimina los espacios.\n","\n","  Parámetros:\n","    df: El DataFrame al que se le aplicarán las modificaciones.\n","\n","  Retorno:\n","    Un DataFrame con los nombres de las columnas modificados.\n","  \"\"\"\n","  df.columns = df.columns.str.upper().str.replace(\" \", \"_\")\n","  return df\n","\n","# Aplicamos la función a cada DataFrame\n","df_hechos = convertir_columnas(df_hechos)\n","df_victimas = convertir_columnas(df_victimas)"]},{"cell_type":"markdown","metadata":{},"source":["Hacemos una presentacón de como esta presentada la informacion en nuestros DataFrames:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_hechos.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_victimas.head(2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfSummary(df_hechos)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dfSummary(df_victimas)"]},{"cell_type":"markdown","metadata":{},"source":["### <span style=\"color: #8DECB4\">**3-Unificar DataSet**</span>"]},{"cell_type":"markdown","metadata":{},"source":["Los datasets comparten información repetida por lo que debemos eliminar en alguno de ellos estas columnas que se repetirán en el df final:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Se eliminan las columnas repetidas\n","df_victimas = df_victimas.drop(['FECHA', 'AAAA', 'MM', 'DD', 'VICTIMA'], axis=1)\n","df_victimas.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_victimas"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["df_hechos"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(df_hechos)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["len(df_victimas)"]},{"cell_type":"markdown","metadata":{},"source":["Para fusionar los df se utiliza la función Merge."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["viales_clean = df_victimas.merge(df_hechos, on=\"ID\", how=\"left\")\n","viales_clean.columns"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["viales_clean"]},{"cell_type":"markdown","metadata":{},"source":["## <span style=\"color: #FFDD95\">**Carga**</span>"]},{"cell_type":"markdown","metadata":{},"source":["En cierta parte de nuestro dataset tenemos un salto de pagina que genera un error en el guardado del csv, por lo que con el código siguiente eliminamos el espacio y el dataset se guarda correctamente."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Eliminar saltos de línea en todas las columnas\n","for col in viales_clean.columns:\n","    viales_clean[col] = viales_clean[col].astype(str).str.replace('\\n', ' ').str.replace('\\r', ' ')"]},{"cell_type":"markdown","metadata":{},"source":["Como hay errores en la columna MM la pasamos a entero para luego usarla en la formula de creación de la columna Semestre:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convertir la columna 'MM' a tipo numérico si es necesario\n","viales_clean['MM'] = pd.to_numeric(viales_clean['MM'], errors='coerce')\n","\n","# Crear la columna 'Semestre' basada en el mes\n","viales_clean['Semestre'] = viales_clean['MM'].apply(lambda x: '1' if x <= 6 else '2')\n","\n","viales_clean"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Archivos DataFrame a exportar\n","viales_clean.to_csv('viales_clean.csv', index=False)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.1"}},"nbformat":4,"nbformat_minor":0}
